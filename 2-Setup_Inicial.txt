----------------------------------------------------------------------------------------------------
---------					Instalação inicial Hadoop					 		    ----------------
----------------------------------------------------------------------------------------------------
cd (Voltar a diretório inicial)
sudo nano .bashrc
Adicionar:
export HADOOP_HOME"/usr/local/hadoop"
export HADOOP_CONF_DIR"/usr/local/hadoop/etc/hadoop"
export HADOOP_MAPRED_HOME"/usr/local/hadoop"
export HADOOP_COMMON_HOME"/usr/local/hadoop"
export HADOOP_HDFS_HOME"/usr/local/hadoop"
export YARN_HOME"/usr/local/hadoop"

export JAVA_HOME="/usr/lib/jvm/java-7-openjdk-amd64"

export PATH=$PATH:/usr/local/hadoop

----------------------------------------------------------------------------------------------------

mkdir /var/hdfs/tmp
mkdir /var/hdfs/namenodelogs
mkdir /var/hdfs/data
sudo chown -R hduser:hadoop /var/hdfs

----------------------------------------------------------------------------------------------------

/usr/local/hadoop/etc/hadoop/core-site.xml:
<configuration>
    <property>
        <name>fs.default.name</name>
        <value>hdfs://namenode:10001</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/var/hdfs/tmp</value>
    </property>
</configuration>

----------------------------------------------------------------------------------------------------

/etc/hadoop/hdfs-site.xml:
<configuration>
   <property> 
      <name>dfs.namenode.name.dir</name> 
      <value>/var/hdfs/namenodelogs</value> 
      <final>true</final> 
   </property>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>/var/hdfs/data</value>
	</property>
</configuration>

----------------------------------------------------------------------------------------------------
---------					Inicializando					 		    ----------------
----------------------------------------------------------------------------------------------------
/usr/local/hadoop/bin/hdfs namenode -format
/usr/local/hadoop/sbin/start-dfs.sh
jps(Módulos iniciados)
Criar duas pastas para o MapReduce:
bin/hdfs dfs -mkdir /var/hdfs/mapreduce
bin/hdfs dfs -mkdir /var/hdfs/mapreduce

----------------------------------------------------------------------------------------------------
---------					Instalação YARN(MapReduce)					 		    ----------------
----------------------------------------------------------------------------------------------------
/usr/local/hadoop/etc/hadoop/mapred-site.xml:

<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapred.job.tracker</name>
        <value>resourcemanager:10002</value>
    </property>
</configuration>

----------------------------------------------------------------------------------------------------

/usr/local/hadoop/etc/hadoop/yarn-site.xml:

<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
	<property>
	 <name>yarn.resourcemanager.scheduler.address</name>
	 <value>namenode:8030</value>
	</property>
	<property>
	 <name>yarn.resourcemanager.address</name>
	 <value>namenode:8032</value>
	</property>
	<property>
	  <name>yarn.resourcemanager.webapp.address</name>
	  <value>namenode:8088</value>
	</property>
	<property>
	  <name>yarn.resourcemanager.resource-tracker.address</name>
	  <value>namenode:8031</value>
	</property>
	<property>
	  <name>yarn.resourcemanager.admin.address</name>
	  <value>namenode:8033</value>
	</property>
</configuration>

----------------------------------------------------------------------------------------------------
Iniciar Mapreduce(YARN):
/usr/local/hadoop/sbin/start-yarn.sh